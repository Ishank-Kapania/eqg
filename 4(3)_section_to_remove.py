# Hardcoded dictionary (shortened for demo)
section_dict = {
    "Introduction": 11376,
    "Conclusion": 7828,
    "Related Work": 6455,
    "Acknowledgements": 5103,
    "Limitations": 4438,
    "Experiments": 4067,
    "Results": 3681,
    "Ethics Statement": 3252,
    "": 3116,
    "Acknowledgments": 2481,
    "Ethical Considerations": 1934,
    "Experimental Setup": 1770,
    "Methodology": 1627,
    "Datasets": 1578,
    "Discussion": 1439,
    "Method": 1424,
    "Baselines": 1335,
    "Ablation Study": 1322,
    "Model": 1204,
    "Analysis": 1196,
    "Conclusions": 1187,
    "Main Results": 1149,
    "A Appendix": 1094,
    "Dataset": 1009,
    "Implementation Details": 974,
    "Evaluation": 897,
    "Acknowledgement": 882,
    "Models": 828,
    "Background": 815,
    "Conclusion and Future Work": 800,
    "Evaluation Metrics": 769,
    "Methods": 748,
    "Case Study": 698,
    "Experimental Results": 653,
    "Data": 638,
    "Experimental Settings": 602,
    "Human Evaluation": 568,
    "Results and Analysis": 562,
    "Related work": 560,
    "Results and Discussion": 547,
    "Experiment": 494,
    "Related Works": 488,
    "Approach": 471,
    "Error Analysis": 424,
    "Preliminaries": 409,
    "Setup": 399,
    "Problem Formulation": 377,
    "C Did you run computational experiments?": 361,
    "Training": 354,
    "Data Collection": 351,
    "Metrics": 336,
    "Ablation Studies": 325,
    "Qualitative Analysis": 311,
    "Overview": 308,
    "Experiments and Results": 304,
    "Appendix": 290,
    "Conclusions and Future Work": 289,
    "Problem Definition": 281,
    "Task Definition": 256,
    "Ethical Statement": 246,
    "Automatic Evaluation": 244,
    "Experiment Setup": 235,
    "Settings": 233,
    "Model Architecture": 219,
    "Bibliographical References": 219,
    "Ethical Consideration": 212,
    "Experimental setup": 183,
    "Ethical considerations": 182,
    "Acknowledgment": 178,
    "Task Formulation": 177,
    "Dataset Construction": 176,
    "Baseline Models": 175,
    "Preliminary": 168,
    "Annotation": 167,
    "Inference": 165,
    "Implementation": 165,
    "ACL 2023 Responsible NLP Checklist": 160,
    "A Implementation Details": 154,
    "Experimental Setting": 147,
    "Proposed Method": 146,
    "Overall Results": 144,
    "Discussion and Conclusion": 142,
    "B Implementation Details": 142,
    "Limitation": 141,
    "Background and Related Work": 135,
    "Training Details": 134,
    "Experiment Settings": 130,
    "Ethics": 130,
    "Dataset Statistics": 126,
    "Problem Statement": 124,
    "Model Training": 120,
    "Baseline Methods": 119,
    "Our Approach": 119,
    "Motivation": 117,
    " ": 116,
    "Baseline": 114,
    "Dataset Analysis": 113,
    "Tasks": 111,
    "Source": 110,
    "A Appendices": 109,
    "Training and Inference": 109,
    "Further Analysis": 107,
    "Analysis and Discussion": 107,
    "Annotation Process": 105,
    "Data Augmentation": 104,
    "Ablation study": 103,
    "Task": 102,
    "Original": 101,
    "Training Objective": 100,
    "Data Analysis": 99,
    "Architecture": 99,
    "Future Work": 98,
    "Experiment Results": 98,
    "B1. Did you cite the creators of artifacts you used?": 97,
    "Input": 96,
    "Main results": 95,
    "Data Annotation": 95,
    "Overall Performance": 94,
    "Ethics statement": 92,
    "Compared Methods": 90,
    "Encoder": 89,
    "Broader Impact": 89,
    "Discussions": 89,
    "Summary": 88,
    "Evaluation metrics": 88,
    "Corpus": 88,
    "Experimental Setups": 87,
    "Contrastive Learning": 87,
    "Context": 86,
    "Evaluation Results": 85,
    "Visualization": 85,
    "Evaluation Metric": 84,
    "Hyperparameters": 82,
    "Preprocessing": 81,
    "Dataset Creation": 79,
    "Prompt": 79,
    "Reference": 79,
    "Ethical Concerns": 78,
    "C Implementation Details": 78,
    "B Did you use or create scientific artifacts?": 78,
    "Pre-training": 77,
    "4": 76,
    "Implementation details": 76,
    "Appendices": 75,
    "Fine-tuning": 75,
    "Tasks and Datasets": 74,
    "Statistics": 74,
    "Ethical Considerations and Limitations": 74,
    "Task Description": 74,
    "Conclusion & Future Work": 74,
    "Ours": 73,
    "Case Studies": 73,
    "Knowledge Distillation": 71,
    "Error analysis": 71,
    "Contributions": 71,
    "Question": 71,
    "Datasets and Metrics": 71,
    "Limitations and Future Work": 68,
    "Quantitative Analysis": 67,
    "Data Preparation": 66,
    "Setting": 66,
    "Performance Comparison": 66,
    "Ablations": 65,
    "Evaluation Setup": 65,
    "Machine Translation": 63,
    "2": 63,
    "Data Statistics": 62,
    "Proposed Approach": 62,
    "Ethics and Broader Impact": 62,
    "Metric": 62,
    "A. Appendix": 62,
    "A Experimental Details": 61,
    "Loss Function": 61,
    "Datasets and Evaluation Metrics": 61,
    "Question:": 60,
    "Results and Discussions": 60,
    "Annotation Guidelines": 59,
    "2.": 58,
    "Model Overview": 58,
    "Results and discussion": 58,
    "Quantitative Results": 58,
    "5": 58,
    "Optimization": 57,
    "Experiments and Analysis": 57,
    "A Datasets": 57,
    "Decoder": 56,
    "B Additional Results": 56,
    "Gold": 55,
    "C Additional Results": 55,
    "Experimental Evaluation": 54,
    "Experimental results": 54,
    "Qualitative Results": 54,
    "Named Entity Recognition": 54,
    "Dataset Collection": 53,
    "USER:": 53,
    "Experimental settings": 53,
    "Results & Discussion": 53,
    "Experimental Details": 51,
    "Inter-Annotator Agreement": 51,
    "Case study": 50,
    "References": 49,
    "Human Evaluation Results": 49,
    "Framework": 49,
    "Ablation": 49,
    "A Dataset Details": 49,
    "Model Analysis": 49,
    "A Training Details": 49,
    "Question Generation": 48,
    "Problem Setup": 48,
    "Related works": 48,
    "Limitations and Ethical Considerations": 48,
    "Language": 47,
    "Data Source": 47,
    "Examples": 47,
    "Result": 46,
    "Experimental Design": 46,
    "Analyses": 46,
    "Results and Analyses": 46,
    "Data collection": 46,
    "3.": 46,
    "Data Preprocessing": 45,
    "Language Models": 45,
    "A Dataset Statistics": 45,
    "Annotation Procedure": 45,
    "A.2 Implementation Details": 45,
    "Question Answering": 45,
    "Manual Evaluation": 44,
    "B Hyperparameters": 44,
    "Human evaluation": 44,
    "Text": 44,
    "Graph Construction": 44,
    "B Training Details": 43,
    "Benchmarks": 43,
    "A Hyperparameters": 43,
    "Classification": 43,
    "Corpora": 42,
    "Experimentation": 42,
    "Discussion and Future Work": 42,
    "Ethics Considerations": 42,
    "Features": 42,
    "Sentiment Analysis": 42,
    "Annotation Scheme": 42,
    "Summarization": 41,
    "Qualitative analysis": 41,
    "Applications": 41,
    "Large Language Models": 41,
    "Conclusion and future work": 41,
    "Data Sources": 40,
    "System": 40,
    "Example": 40,
    "Quality Control": 40,
    "Conclusion and Discussion": 40,
    "Approaches": 39,
    "Automatic Evaluation Results": 39,
    "Previous Work": 39,
    "Language Modeling": 39,
    "Participants": 39,
    "Intrinsic Evaluation": 39,
    "3": 39,
    "Procedure": 39,
    "Corpus Statistics": 39,
    "A4. Have you used AI writing assistants when working on this paper?": 39,
    "User": 38,
    "B Experimental Details": 38,
    "Training Data": 38,
    "Ablation Analysis": 38,
    "Category": 38,
    "Training Setup": 38,
    "Dataset Description": 38,
    "Ethical Impact": 38,
    "Learning": 37,
    "Decoding": 37,
    "5.": 37,
    "Instruction": 37,
    "D Case Study": 36,
    "D Implementation Details": 36,
    "Downstream Tasks": 36,
    "A.1 Implementation Details": 36,
    "Experimental setting": 36,
    "Result Analysis": 36,
    "Input:": 36,
    "Discussion and Conclusions": 36,
    "Comparison Methods": 36,
    "Human Annotation": 36,
    "Qualitative Evaluation": 36,
    "Proposed Model": 36,
    "Challenges": 36,
    "A2. Did you discuss any potential risks of your work?": 36,
    "A1. Did you describe the limitations of your work?": 36,
    "Evaluation Datasets": 35,
    "Efficiency": 35,
    "As shown in": 35,
    "Main Result": 35,
    "Data Construction": 35,
    "Feature Extraction": 35,
    "Domain Adaptation": 35,
    "Wife": 35,
    "5:": 35,
    "Training Objectives": 34,
    "Domain": 34,
    "ChatGPT": 34,
    "B Datasets": 34,
    "Baseline Systems": 34,
    "Ground Truth": 34,
    "Ethics Consideration": 34,
    "Query": 34,
    "Label": 34,
    "Prompt:": 34,
    "Neural Machine Translation": 34,
    "Ethical considerations and limitations": 34,
    "Evaluation Methods": 33,
    "4.": 33,
    "A Experimental Setup": 33,
    "Notations": 33,
    "7:": 33,
    "Evaluation Protocol": 33,
    "Results & Analysis": 33,
    "Impact Statement": 33,
    "Evaluation Tasks": 32,
    "EXAMPLE": 32,
    "Experiment Setting": 32,
    "Broader Impact Statement": 32,
    "Experimental Results and Analysis": 32,
    "A.1 Datasets": 32,
    "Overall Framework": 32,
    "Joint Training": 32,
    "Performance Evaluation": 32,
    "Output:": 32,
    "Husband": 32,
    "Research Questions": 32,
    "Quantitative Evaluation": 32,
    "Modeling": 32,
    "Notation": 32,
    "Context:": 32,
    "Our Method": 32,
    "Hyper-parameters": 31,
    "Response Generation": 31,
    "Retriever": 31,
    "Corpus Creation": 31,
    "Baseline models": 31,
    "Findings": 31,
    "Our Model": 31,
    "Systems": 30,
    "Retrieval": 30,
    "System Overview": 30,
    "Target": 30,
    "Evaluation Settings": 30,
    "Model Configuration": 30,
    "Pre-processing": 30,
    "Comparison Models": 30,
    "Detailed Analysis": 30
}

def get_inclusion_decisions(prompt_num):
    print(f"\n=== Pass {prompt_num}: Decide whether to include each section ===")
    decisions = {}
    for section in section_dict:
        while True:
            ans = input(f"Include section '{section}'? (y/n): ").strip().lower()
            if ans in ['y', 'n']:
                decisions[section] = (ans == 'y')
                break
            else:
                print("Invalid input. Please enter 'y' or 'n'.")
    return decisions

def check_consistency(dec1, dec2):
    inconsistent_keys = []
    for key in dec1:
        if dec1[key] != dec2[key]:
            print(f"Inconsistency detected in section: '{key}'")
            inconsistent_keys.append(key)
    return inconsistent_keys

def resolve_final_decisions(first_pass, inconsistent_keys):
    print("\n=== Final Decision for Inconsistent Sections ===")
    for section in inconsistent_keys:
        while True:
            ans = input(f"Final decision for section '{section}' (include? y/n): ").strip().lower()
            if ans in ['y', 'n']:
                first_pass[section] = (ans == 'y')
                break
            else:
                print("Invalid input. Please enter 'y' or 'n'.")
    return first_pass

def main():
    first_pass = get_inclusion_decisions(1)
    second_pass = get_inclusion_decisions(2)

    print("\n=== Consistency Check ===")
    inconsistent_sections = check_consistency(first_pass, second_pass)

    if not inconsistent_sections:
        print("✅ Decisions are consistent between both passes.")
    else:
        print("❌ Inconsistencies found.")
        first_pass = resolve_final_decisions(first_pass, inconsistent_sections)

    excluded_sections = [section for section, include in first_pass.items() if not include]
    print("\n=== Final Excluded Sections ===")
    print(", ".join(excluded_sections))

if __name__ == "__main__":
    main()
